nohup: 忽略输入
epoch,train_loss,dev_loss,arc_acc,lab_acc
loading data...
# train sentences 31864
# dev sentences 7967
creating model...
BiAffineParser(
  (word_embed): Embedding(19706, 100)
  (pos_embed): Embedding(48, 28)
  (drop): Dropout(p=0.33)
  (lstm): LSTM(128, 512, num_layers=2, batch_first=True, dropout=0.33, bidirectional=True)
  (arc_mlp_h): MLP(
    (layers): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=1024, out_features=100, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.33)
      )
    )
  )
  (arc_mlp_d): MLP(
    (layers): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=1024, out_features=100, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.33)
      )
    )
  )
  (lab_mlp_h): MLP(
    (layers): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=1024, out_features=100, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.33)
      )
    )
  )
  (lab_mlp_d): MLP(
    (layers): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=1024, out_features=100, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.33)
      )
    )
  )
  (arc_attn): BiAffineAttn()
  (lab_attn): BiAffineAttn()
)
Epoch 0 train_loss 1.656 dev_loss 0.549 arc_acc 89.12% lab_acc 95.29% time 742.3 sec
0, 1.656, 0.549, 89.12%, 95.29%
Epoch 1 train_loss 0.626 dev_loss 0.442 arc_acc 91.42% lab_acc 96.38% time 749.3 sec
1, 0.626, 0.442, 91.42%, 96.38%
Epoch 2 train_loss 0.515 dev_loss 0.408 arc_acc 92.05% lab_acc 96.72% time 757.7 sec
2, 0.515, 0.408, 92.05%, 96.72%
